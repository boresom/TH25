---
title: "Исследование метаданных DNS трафика"
format: 
  md:
    output-file: README.md
---

## Цель работы

1. Зекрепить практические навыки использования языка программирования R для обработки данных;
2. Закрепить знания основных функций обработки данных экосистемы tidyverse языка R;
3. Закрепить навыки исследования метаданных DNS трафика.

## Исходные данные

1. Rstudio Desktop;
2. Интерпретатор языка R 4.1;
3. Экосистема tidyverse.
     
## Задание

Используя программный пакет dplyr, освоить анализ DNS логов с помощью языка программирования R.

## Подготовка данных

1. Импортируйте данные DNS – https://storage.yandexcloud.net/dataset.ctfsec/dns.zip

```{r}
temp_dir <- tempdir()
download.file(url = "https://storage.yandexcloud.net/dataset.ctfsec/dns.zip", destfile = file.path(temp_dir, "dns.zip"),  mode = "wb")
unzip(zipfile = file.path(temp_dir, "dns.zip"), exdir = temp_dir)
```

### Обработка данных

2 и 3. Добавьте пропущенные данные о структуре данных (назначении столбцов) и преобразуйте данные в столбцах в нужный формат

```{r}
library(httr)
library(jsonlite)
library(readr)
library(dplyr)
library(stringr)
library(tidyr)
library(knitr)
column_names <- c(
  "timestamp", "uid", "source_ip", "source_port", "destination_ip", 
  "destination_port", "protocol", "transaction_id", "query", "qclass", 
  "qclass_name", "qtype", "qtype_name", "rcode", "rcode_name", 
  "AA", "TC", "RD", "RA", "Z", "answers", "TTLS", "rejected"
)
log_files <- list.files(temp_dir, pattern = "\\.log$", full.names = TRUE)
dns_data <- invisible(read_delim(
  log_files[1],
  delim = "\t",
  col_names = column_names,
  comment = "#",
  na = c("", "NA", "-"),
  trim_ws = TRUE,
  show_col_types = FALSE
)) %>% as_tibble()
dns_data2 <- dns_data %>%
  mutate(
    timestamp = as.POSIXct(timestamp, origin = "1970-01-01"),
    source_port = as.numeric(source_port),
    destination_port = as.numeric(destination_port),
    transaction_id = as.numeric(transaction_id),
    qclass = as.numeric(qclass),
    qtype = as.numeric(qtype),
    rcode = as.numeric(rcode),
  ) %>% as_tibble()
head(dns_data2,10) %>% knitr::kable(format='markdown')
```

4. Сколько участников информационного обмена в сети Доброй Организации?

```{r}
length(unique(c(unique(dns_data2$source_ip),unique(dns_data2$destination_ip))))
```

5. Соотношение участников обмена внутри сети и участников обращений к внешним ресурсам.

```{r}
unique_ips = unique(c(unique(dns_data2$source_ip),unique(dns_data2$destination_ip)))

is_internal_ip <- function(ip_str) {
  if (is.na(ip_str)) return(FALSE)
  internal_patterns <- c(
    "^10\\.",                    # 10.0.0.0
    "^172\\.(1[6-9]|2[0-9]|3[0-1])\\.", # 172.16.0.0
    "^192\\.168\\.",             # 192.168.0.0
    "^127\\."                    # 127.0.0.0
  )
  return(any(sapply(internal_patterns, function(p) str_detect(ip_str, p))))
}

unique_ip_df <- data.frame(ip = unique_ips) %>%  mutate(is_internal = sapply(ip, is_internal_ip), type = ifelse(is_internal, "Internal", "External"))

ip_counts <- unique_ip_df %>% group_by(type) %>%summarise(unique_count = n())
print(ip_counts)
```

6. Найдите топ-10 участников сети, проявляющих наибольшую сетевую активность.

```{r}
all_ips <- dns_data2 %>%
  select(source_ip, destination_ip) %>%
  tidyr::pivot_longer(
    cols = everything(),
    names_to = "role",
    values_to = "ip_address"
  )

active_participants <- all_ips %>%
  filter(!is.na(ip_address)) %>%
  group_by(ip_address) %>%
  summarise(
    request_count = n()
  ) %>%
  ungroup() %>%
  arrange(desc(request_count))

print(head(active_participants, 10))
```

7.  Найдите топ-10 доменов, к которым обращаются пользователи сети и соответственное количество обращений

```{r}
domain_counts <- dns_data2 %>%
  filter(!is.na(query)) %>%
  group_by(query) %>%
  summarise(
    request_count = n()
  ) %>%
  ungroup() %>%
  arrange(desc(request_count))

print(head(domain_counts, 10))

```

8. Опеределите базовые статистические характеристики (функция summary() ) интервала времени между последовательными обращениями к топ-10 доменам.

```{r}
top_10_domains_list <- head(domain_counts, 10) %>% pull(query)

interval_data <- dns_data2 %>%
  filter(query %in% top_10_domains_list) %>%
  arrange(query, timestamp) %>%
  group_by(query) %>%
  mutate(
    time_diff = lead(timestamp) - timestamp
  ) %>%
  filter(!is.na(time_diff)) %>%
  ungroup()

summary_results <- interval_data %>%
    group_by(query) %>%
    summarise(
      Min = min(time_diff),
      Q1 = quantile(time_diff, 0.25),
      Median = median(time_diff),
      Mean = mean(time_diff),
      Q3 = quantile(time_diff, 0.75),
      Max = max(time_diff),
      Units = unique(units(time_diff))
    )

print(summary_results)
```

9. Часто вредоносное программное обеспечение использует DNS канал в качестве канала управления, периодически отправляя запросы на подконтрольный злоумышленникам DNS сервер. По периодическим запросам на один и тот же
домен можно выявить скрытый DNS канал. Есть ли такие IP адреса в исследуемом датасете?

```{r}
library(stats)
MIN_REQUESTS <- 10

potential_tunnels <- dns_data2 %>%
  select(timestamp, source_ip, query) %>%
  filter(!is.na(query), !is.na(source_ip)) %>%
  group_by(source_ip, query) %>%
  filter(n() >= MIN_REQUESTS) %>%
  arrange(timestamp) %>%
  mutate(
    time_interval = as.numeric(timestamp - lag(timestamp), units = "secs")
  ) %>%
  filter(!is.na(time_interval)) %>%
  ungroup()

tunnel_statistics <- potential_tunnels %>%
  group_by(source_ip, query) %>%
  summarise(
    total_requests = n() + 1,
    mean_interval_sec = round(mean(time_interval), 2),
    sd_interval_sec = round(sd(time_interval), 2),
    cv_ratio = sd_interval_sec / mean_interval_sec,
    
    .groups = 'drop'
  ) %>%
  arrange(desc(total_requests), cv_ratio)

potential_tunneling_ips <- tunnel_statistics %>%
  filter(cv_ratio < 0.1) %>%
  select(source_ip, query, total_requests, mean_interval_sec, sd_interval_sec, cv_ratio)

print(potential_tunneling_ips %>% pull(source_ip) %>% unique())
```

9. Определите местоположение (страну, город) и организацию-провайдера для топ-10 доменов. Для этого можно использовать сторонние сервисы, например http://ip-api.com (API-эндпоинт – http://ip-api.com/json).

```{r}
get_geo_info <- function(ip) {
  if (is.na(ip) || ip == "") {
     return(tibble(
      ip_address = NA_character_,
      country = NA,
      city = NA,
      isp = NA
    ))
  }
  if (grepl("^(10\\.|192\\.168\\.|172\\.(1[6-9]|2[0-9]|3[0-1])\\.)", ip)) {
    return(tibble(
      ip_address = ip,
      country = "Internal IP",
      city = "Internal IP",
      isp = "Internal IP"
    ))
  }
  url <- paste0("http://ip-api.com/json/", ip)
  response <- GET(url)
  if (status_code(response) == 200) {
    data <- fromJSON(content(response, "text"))
    if (data$status == "success") {
      return(tibble(
        ip_address = ip,
        country = data$country,
        city = data$city,
        isp = data$isp
      ))
    } else {
      return(tibble(
        ip_address = ip,
        country = paste("API error"),
        city = paste("API errors"),
        isp = paste("API error")
      ))
    }
  } else {
    return(tibble(
      ip_address = ip,
      country = "API error",
      city = "API error",
      isp = "API error"
    ))
  }
}

dns_with_dest_ip <- dns_data2 %>%
  filter(!is.na(destination_ip)) %>%
  select(query, destination_ip) %>%
  distinct()
top_10_domains <- dns_data2%>%count(query, sort = TRUE) %>%
  as_tibble() %>% head(10)
top_10_domains
relevant_dns <- dns_with_dest_ip %>%
  filter(query %in% top_10_domains$query)
geo_results_df <- tibble(
  ip_address = character(),
  country = character(),
  city = character(),
  isp = character()
)
unique_ips_to_check <- unique(relevant_dns$destination_ip)
for (ip in unique_ips_to_check) {
  geo_info_row <- get_geo_info(ip)
  geo_results_df <- bind_rows(geo_results_df, geo_info_row)
}
domain_geo_info_final <- relevant_dns %>%
  left_join(geo_results_df, by = c("destination_ip" = "ip_address")) %>%
  rename(ip_address = destination_ip) %>%
  select(domain = query, ip_address, country, city, isp)
domain_order_factor <- factor(domain_geo_info_final$domain, levels = top_10_domains$query)
domain_geo_info_final_sorted <- domain_geo_info_final %>%
  mutate(domain_order = domain_order_factor) %>%
  arrange(domain_order) %>%
  select(-domain_order)
print(domain_geo_info_final_sorted)
```

## Оценка результата

 В результате лабораторной работы мы проанализировали DNS трафик Доброй Организации с помощью языка R.

## Вывод

Таким образом, мы развили практические навыки использования языка программирования R для обработки данных, закрепили знания базовых типов данных языка R, развили практические навыки использования функций обработки DNS трафика. 

